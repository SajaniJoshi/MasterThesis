{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MXNET_CUDNN_LIB_CHECKING\"] = \"0\"\n",
    "os.environ[\"MXNET_CUDNN_AUTOTUNE_DEFAULT\"] = \"0\"\n",
    "import sys\n",
    "path_to_adds = [r\"D:\\Source\\Test\", r\"D:\\Source\\Test\\TextMxnet\\examples\\polygonExtractor\", \n",
    "                r\"D:\\Source\\Test\\TextMxnet\\examples\\Metadata.py\", r\"D:\\Source\\Test\\TextMxnet\\examples\\image_Dictionary.py\"]\n",
    "for path_to_add in path_to_adds:\n",
    "    if path_to_add not in sys.path:\n",
    "        sys.path.append(path_to_add)\n",
    "        \n",
    "# Remove duplicates while preserving order\n",
    "sys.path = list(dict.fromkeys(sys.path))\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd\n",
    "from mxnet.lr_scheduler import LRScheduler\n",
    "from decode.FracTAL_ResUNet.models.semanticsegmentation.FracTAL_ResUNet import FracTAL_ResUNet_cmtsk\n",
    "from decode.FracTAL_ResUNet.nn.loss.mtsk_loss import mtsk_loss\n",
    "from decode.postprocessing.instance_segmentation import InstSegm\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import measure\n",
    "from shapely.geometry import Polygon\n",
    "import geopandas as gpd\n",
    "\n",
    "from polygon_extractor import PolygonExtractor\n",
    "from image_Dictionary import ImageDict\n",
    "\n",
    "loss_path_plot = r\"D:\\Source\\Test\\data\\Output\\Fractal\\Loss\\loss_VNIR_plot.png\"\n",
    "loss_path_csv = r\"D:\\Source\\Test\\data\\Output\\Fractal\\Loss\\loss_VNIR.csv\"\n",
    "result_path = r\"D:\\Source\\Test\\data\\Output\\Fractal\\Result\"\n",
    "trained_model_path = r\"D:\\Source\\Test\\data\\Output\\Fractal\\Model_VNIR_params\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to load images and masks and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ImageDict( r\"D:\\Source\\Test\\data\\2022\\BB\\08X_Features_Multi\", False)\n",
    "image_dict = images.load_tif_files()\n",
    "masks = ImageDict(r\"D:\\Source\\Test\\data\\2022\\BB\\XX_Reference_Masks_ResUNetA\", True)\n",
    "mask_dict = masks.load_tif_files()\n",
    "train_ids, val_ids = train_test_split(list(image_dict.keys()), test_size=0.2, random_state=42)\n",
    "print(len(image_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# default train params and initialize FracTAL_ResUNet_cmtsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "ctx = mx.cpu()  \n",
    "\n",
    "num_classes = 2\n",
    "nfilters_init = 32\n",
    "depth = 6\n",
    "\n",
    "def createFracTAL_ResUNetModel(isLoad, path):\n",
    "    net = FracTAL_ResUNet_cmtsk(nfilters_init, depth, num_classes)\n",
    "    net.initialize(ctx=ctx)\n",
    "    if isLoad:\n",
    "        net.load_parameters(path, ctx=ctx)\n",
    "    net.hybridize()\n",
    "    return net\n",
    "\n",
    "# Some optimizer of your choice, recommend Adam\n",
    "net = createFracTAL_ResUNetModel(False, \"\")\n",
    "trainer = mx.gluon.trainer.Trainer(net.collect_params(), 'adam', {'learning_rate': learning_rate})\n",
    "\n",
    "# Example usage inside a training loop\n",
    "class ReduceLROnPlateau(LRScheduler):\n",
    "    def __init__(self, trainer, patience=5, factor=0.1, min_lr=1e-6, mode='min', threshold=1e-4, cooldown=0):\n",
    "        super(ReduceLROnPlateau, self).__init__()\n",
    "        self.trainer = trainer\n",
    "        self.patience = patience\n",
    "        self.factor = factor\n",
    "        self.min_lr = min_lr\n",
    "        self.mode = mode\n",
    "        self.threshold = threshold\n",
    "        self.cooldown = cooldown\n",
    "        self.best = None\n",
    "        self.num_bad_epochs = 0\n",
    "        self.cooldown_counter = 0\n",
    "    \n",
    "    def step(self, metric):\n",
    "        # Cooldown logic to delay LR changes\n",
    "        if self.cooldown_counter > 0:\n",
    "            self.cooldown_counter -= 1\n",
    "            return\n",
    "\n",
    "        # Set the best metric and determine if LR needs to be reduced\n",
    "        if self.best is None or \\\n",
    "           (self.mode == 'min' and metric < self.best - self.threshold) or \\\n",
    "           (self.mode == 'max' and metric > self.best + self.threshold):\n",
    "            self.best = metric\n",
    "            self.num_bad_epochs = 0\n",
    "        else:\n",
    "            self.num_bad_epochs += 1\n",
    "\n",
    "        # Reduce LR if we exceed patience\n",
    "        if self.num_bad_epochs >= self.patience:\n",
    "            new_lr = max(self.trainer.learning_rate * self.factor, self.min_lr)\n",
    "            self.trainer.set_learning_rate(new_lr)\n",
    "            print(f'Reducing learning rate to {new_lr}')\n",
    "            self.num_bad_epochs = 0\n",
    "            self.cooldown_counter = self.cooldown\n",
    "            \n",
    "\n",
    "# Example usage inside a training loop\n",
    "reduce_lr = ReduceLROnPlateau(trainer, patience=5, factor=0.1)\n",
    "# get default Tanimoto loss (depth=0) function for multitasking operation\n",
    "myMTSKL = mtsk_loss(depth=0, NClasses=num_classes)\n",
    "\n",
    "class LossModel():\n",
    "    def __init__(self, epoch, loss, val_loss, net):\n",
    "        self.epoch = epoch\n",
    "        self.loss = loss\n",
    "        self.val_loss = val_loss\n",
    "        self.net = net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track epoch losses \n",
    "# backward with multitasking operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "loss_each_epoch = []\n",
    "model_list = []\n",
    "patience = 5  # Number of epochs to wait for improvement\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "\n",
    "print('Start training now')\n",
    "for epoch in range(epochs): # Train for as many num_epochs you want\n",
    "    print(f'current epoch: {epoch}')\n",
    "    train_loss = 0.0     # compute training loss\n",
    "    for id in train_ids[:20]: # NOTE: img/mask contain batches of images/lables each with the size (batch_size, H, W)\n",
    "        print(id)\n",
    "        img = images.getImage(id, image_dict)\n",
    "        mask = mask.getImage(id, mask_dict)\n",
    "        if img is None or mask is None:\n",
    "            continue\n",
    "        # forward + backward\n",
    "        with autograd.record():\n",
    "            ListOfPredictions = net(img)\n",
    "            loss = myMTSKL.loss(ListOfPredictions, mask)\n",
    "        loss.backward()\n",
    "        trainer.step(1)\n",
    "       #using one image so it does not need step trainer.step(1) # update parameters\n",
    "        train_loss += loss.mean().asscalar() # calculate training metrics\n",
    "    current_epoch_loss = train_loss / len(train_ids)  # compute overall loss\n",
    "    train_losses.append(current_epoch_loss)    # now append the epoch loss\n",
    "    \n",
    "    # compute validation loss\n",
    "    val_loss = 0.0\n",
    "    for id in val_ids[:4]:           \n",
    "        img = images.getImage(id, image_dict)\n",
    "        mask = mask.getImage(id, mask_dict)\n",
    "        if img is None or mask is None:\n",
    "            continue\n",
    "        ListOfPredictions = net(img)  # forward only\n",
    "        loss = myMTSKL.loss(ListOfPredictions, mask)  # get loss\n",
    "        val_loss += loss.mean().asscalar() # calculate validation metrics\n",
    "\n",
    "    # compute overall loss\n",
    "    current_epoch_val_loss = val_loss/ len(val_ids)\n",
    "    val_losses.append(current_epoch_val_loss)\n",
    "    \n",
    "    # Track loss and model for analysis    \n",
    "    loss_each_epoch.append({\"Current Epoch\": epoch, \"Traing Loss\": current_epoch_loss, \"Validation loss\": current_epoch_val_loss})\n",
    "    current_model = LossModel(epoch, current_epoch_loss, current_epoch_val_loss, net)\n",
    "    model_list.append(current_model)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Early stopping check\n",
    "    if current_epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = current_epoch_val_loss\n",
    "        epochs_no_improve = 0  # Reset patience counter\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch}!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write each epoch loss in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"Current Epoch\", \"Traing Loss\", \"Validation loss\"]\n",
    "print(loss_each_epoch)\n",
    "with open(loss_path_csv, mode='w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(loss_each_epoch)\n",
    "\n",
    "print(f\"Data saved to {loss_path_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in model_list:\n",
    "    f =  os.path.join(trained_model_path, f\"model_VNIR_{i.epoch}.params\")\n",
    "    i.net.save_parameters(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(loss_path_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetadata(currentMetadata, prediction_to_save):\n",
    "    # Extract metadata from currentMetadata\n",
    "    metadata = {\n",
    "                \"driver\": \"GTiff\",\n",
    "                \"height\": currentMetadata.shape[0],\n",
    "                \"width\": currentMetadata.shape[1],\n",
    "                \"count\": 1,\n",
    "                \"dtype\": prediction_to_save.dtype.name,\n",
    "                \"crs\": currentMetadata.crs,\n",
    "                \"transform\": currentMetadata.transform,\n",
    "                }\n",
    "    return metadata\n",
    "\n",
    "def writePredictionImage(id, name, pre_img, orignalMeta):\n",
    "   path=  os.path.join(result_path, f\"{id}_{name}.tif\")\n",
    "   meta = getMetadata(orignalMeta, pre_img)\n",
    "   with rasterio.open(path, \"w\", **meta) as dst:\n",
    "                dst.write(pre_img, 1)  # Write to band 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_all(id, img, currentMetadata, outputs, pred_segm, pred_bound, inst): \n",
    "    pred_dists = outputs[2][0,1,:,:].asnumpy() \n",
    "    writePredictionImage(id, \"extend\", pred_segm, currentMetadata)\n",
    "    writePredictionImage(id, \"boundary\", pred_bound, currentMetadata)\n",
    "    writePredictionImage(id, \"distance\", pred_dists, currentMetadata)\n",
    "    if img.ndim == 4 and img.shape[0] == 1:  \n",
    "        abc = img[0]  # Remove batch dimension\n",
    "    if abc.ndim == 3 and abc.shape[0] >= 3:  # RGB or multi-channel image\n",
    "        rgb_image = np.transpose(abc[:3], (1, 2, 0))\n",
    "             \n",
    "    rgb_image = (rgb_image - rgb_image.min()) / (rgb_image.max() - rgb_image.min())\n",
    "    rgb_image = (rgb_image * 255).astype(np.uint8)  # Convert to uint8\n",
    "    if rgb_image.ndim == 3 and rgb_image.shape[0] == 3:\n",
    "        rgb_image = np.transpose(rgb_image, (1, 2, 0))  # Convert from (3, H, W) to (H, W, 3)\n",
    "    fig, ax =plt.subplots(1,5, figsize=(30,30))\n",
    "    ax[0].imshow(rgb_image.asnumpy())\n",
    "    ax[1].imshow(pred_segm)\n",
    "    ax[2].imshow(pred_bound)\n",
    "    ax[3].imshow(pred_dists)\n",
    "    ax[4].imshow(inst, cmap=plt.get_cmap('prism'), interpolation=None)\n",
    "    ax[4].set_title(f'Instance Segmentation {id}')\n",
    "    ax[0].set_title(f'Original {id}')\n",
    "    ax[1].set_title(f'Extent Mask {id}')\n",
    "    ax[2].set_title(f'Boundary Mask {id}')\n",
    "    ax[3].set_title(f'Distance Mask {id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_iou(polygon1, polygon2):\n",
    "    \"\"\"\n",
    "    Computes IoU between two polygons using Shapely.\n",
    "    \"\"\"\n",
    "    intersection = polygon1.intersection(polygon2).area\n",
    "    union = polygon1.union(polygon2).area\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_segmentation(id, segmented_image):\n",
    "    \"\"\"\n",
    "    Visualizes an instance-segmented image with unique labels using a color map.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    plt.imshow(segmented_image, cmap='tab20')  # 'tab20' is a colormap with 20 distinct colors\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Instance-Segmented Image with Labels\")\n",
    "    plt.show()\n",
    "    \n",
    "    fig, ax =plt.subplots(figsize=(15,15))\n",
    "    ax.imshow(segmented_image, cmap=plt.get_cmap('prism'), interpolation=None)\n",
    "    ax.set_title('Instance Segmentation')\n",
    "    path=  os.path.join(result_path, f\"{id}_prism.tiff\")\n",
    "    plt.savefig(path)\n",
    "    \n",
    "def visualize_predictions(path, t_ext = 0.2,t_bound = 0.15, num_images=1):    \n",
    "    print(\"Starting visualization\")\n",
    "    net = createFracTAL_ResUNetModel(True, path)\n",
    "    for id in val_ids[:num_images]:  # Limit to 'num_images' for visualization\n",
    "        img = images.getImage(id, image_dict)\n",
    "        currentMetadata = image_dict[id]\n",
    "        with autograd.record():  \n",
    "            outputs = net(img)  \n",
    "            pred_segm  = outputs[0][0,1,:,:].asnumpy()\n",
    "            pred_bound = outputs[1][0,1,:,:].asnumpy()\n",
    "            inst =InstSegm(pred_segm, pred_bound, t_ext=t_ext, t_bound=t_bound)   # perform instance segmentation\n",
    "            visualize_segmentation(id, inst)\n",
    "            visualize_all(id, img, currentMetadata, outputs, pred_segm, pred_bound, inst)\n",
    "            return inst\n",
    "\n",
    "inst= visualize_predictions(r\"D:\\Source\\Test\\data\\Output\\Fractal\\Model_VNIR_params\\model_VNIR_5.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image = nd.array(inst)  \n",
    "ground_truth_image = nd.array(mask_dict[6982].image)\n",
    "extractor  = PolygonExtractor()\n",
    "pred_polygons, gt_polygons =extractor.getPolygons(predicted_image, ground_truth_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pred_polygons))\n",
    "print(len(gt_polygons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.validation import explain_validity\n",
    "def compute_iou(polygon1, polygon2):\n",
    "    \"\"\"\n",
    "    Computes IoU between two polygons using Shapely.\n",
    "    \"\"\"\n",
    "    print(explain_validity(polygon1))\n",
    "    print(explain_validity(polygon2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_results = []\n",
    "for pred_polygon in pred_polygons:\n",
    "    for gt_polygon in gt_polygons:\n",
    "        iou = compute_iou(pred_polygon, gt_polygon)\n",
    "        break\n",
    "        iou_results.append((pred_polygon, gt_polygon, iou))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process MXNet NDArray for vectorization\n",
    "def vectorize_with_mxnet(array_mx, nan_value=np.nan):\n",
    "    \n",
    "    \"\"\"\n",
    "    Converts MXNet NDArray segmentation results into vectorized polygons.\n",
    "    \n",
    "    Parameters:\n",
    "        array_mx (mxnet.nd.NDArray): Input segmentation array in MXNet format.\n",
    "        nan_value (float): Value to ignore during processing.\n",
    "        \n",
    "    Returns:\n",
    "        geopandas.GeoDataFrame: GeoDataFrame containing polygons.\n",
    "    \"\"\"\n",
    "    # Convert to numpy array for processing\n",
    "    array = array_mx.asnumpy()\n",
    "    array = np.nan_to_num(array, nan=-1)\n",
    "\n",
    "    polygons = []\n",
    "    labels = []\n",
    "\n",
    "    for region_label in np.unique(array):\n",
    "        print(f\"region_label: {region_label}\")\n",
    "        if region_label == -1:  # Skip placeholder (-1, representing NaN)\n",
    "            continue\n",
    "\n",
    "        # Extract contours for each labeled region\n",
    "        contours = measure.find_contours(array == region_label, 0.5)\n",
    "\n",
    "        for contour in contours:\n",
    "            #print(contour)\n",
    "            # Ensure the contour has at least 3 points to form a polygon\n",
    "            if len(contour) < 3:\n",
    "                continue\n",
    "\n",
    "            # Convert contour to a Shapely polygon\n",
    "\n",
    "            print(f\"contour[:, ::-1]: {contour[:, ::-1]}\")\n",
    "            polygon = Polygon(contour[:, ::-1])  # Reverse coordinates to (x, y)\n",
    "            \n",
    "            print(f\"polygon.is_valid: {polygon.is_valid}\")\n",
    "\n",
    "            # Keep valid polygons only\n",
    "            if polygon.is_valid:\n",
    "                polygons.append(polygon)\n",
    "                labels.append(region_label)\n",
    "                \n",
    "                \n",
    "            print(f\"polygons: {len(polygons)}\")\n",
    "            print(f\"labels: {labels}\")\n",
    "\n",
    "\n",
    "    # Create GeoDataFrame with polygons and their labels\n",
    "    gdf = gpd.GeoDataFrame({'geometry': polygons, 'label': labels}, crs=\"EPSG:3035\")\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_mxnet = mx.nd.array(insts[0])\n",
    "vectorized_mxnet_gdf = vectorize_with_mxnet(out_mxnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the GeoDataFrame\n",
    "vectorized_mxnet_gdf.plot(column='label', cmap='viridis', legend=True, figsize=(10, 10))\n",
    "plt.title(\"Polygons and Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_results = []\n",
    "for pred_polygon in pred_polygons:\n",
    "    for gt_polygon in gt_polygons:\n",
    "        iou = compute_iou(pred_polygon, gt_polygon)\n",
    "        break\n",
    "        iou_results.append((pred_polygon, gt_polygon, iou))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satellite_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
