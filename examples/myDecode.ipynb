{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"MXNET_CUDNN_LIB_CHECKING\"] = \"0\"\n",
    "os.environ[\"MXNET_CUDNN_AUTOTUNE_DEFAULT\"] = \"0\"\n",
    "import sys\n",
    "path_to_adds = [r\"D:\\Source\\Test\", \n",
    "                r\"D:\\Source\\Test\\TextMxnet\\examples\\polygonExtractor\", \n",
    "                r\"D:\\Source\\Test\\TextMxnet\\examples\\Metadata.py\", \n",
    "                r\"D:\\Source\\Test\\TextMxnet\\examples\\image_Dictionary.py\", \n",
    "                r\"D:\\Source\\Test\\TextMxnet\\examples\\myModel.py\",\n",
    "                r\"D:\\Source\\Test\\TextMxnet\\examples\\myPlots.py\"]\n",
    "for path_to_add in path_to_adds:\n",
    "    if path_to_add not in sys.path:\n",
    "        sys.path.append(path_to_add)\n",
    "        \n",
    "# Remove duplicates while preserving order\n",
    "sys.path = list(dict.fromkeys(sys.path))\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load images and masks and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_Dictionary import ImageDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "images = ImageDict( r\"D:\\Source\\Test\\data\\2022\\BB\\08X_Features_Multi\", False)\n",
    "image_dict = images.load_tif_files()\n",
    "masks = ImageDict(r\"D:\\Source\\Test\\data\\2022\\BB\\XX_Reference_Masks_ResUNetA\", True)\n",
    "mask_dict = masks.load_tif_files()\n",
    "train_ids, val_ids = train_test_split(list(image_dict.keys()), test_size=0.2, random_state=42)\n",
    "print(len(image_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "num_classes = 2\n",
    "ctx = mx.cpu()  \n",
    "depth = 6\n",
    "nfilters_init = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_Train import myTrain\n",
    "my_train = myTrain(images, masks, image_dict, mask_dict, train_ids, val_ids)\n",
    "my_train.trainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import myModel\n",
    "import myPlots\n",
    "print(myModel.__file__)\n",
    "from importlib import reload\n",
    "reload(myModel)\n",
    "print(myPlots.__file__)\n",
    "reload(myPlots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decode.postprocessing.instance_segmentation import InstSegm\n",
    "from myPlots import visualize_segmentation, visualize_all\n",
    "result_path = r\"D:\\Source\\Test\\data\\Output\\Fractal\\Result\"\n",
    "\n",
    "def visualize_predictions(path, t_ext = 0.2,t_bound = 0.15, num_images=1):    \n",
    "    print(\"Starting visualization\")\n",
    "     \n",
    "    netPredict = myModel.MyFractalResUNetcmtsk(True, path, ctx, 32, depth, num_classes)\n",
    "    for id in val_ids[:num_images]:  # Limit to 'num_images' for visualization\n",
    "        img = images.getImage(id, image_dict)\n",
    "        currentMetadata = image_dict[id]\n",
    "        with autograd.record():  \n",
    "            outputs = netPredict.net(img)  \n",
    "            pred_segm  = outputs[0][0,1,:,:].asnumpy()\n",
    "            pred_bound = outputs[1][0,1,:,:].asnumpy()\n",
    "            inst =InstSegm(pred_segm, pred_bound, t_ext=t_ext, t_bound=t_bound)   # perform instance segmentation\n",
    "            visualize_segmentation(id, inst, result_path)\n",
    "            visualize_all(id, img, currentMetadata, outputs, pred_segm, pred_bound, inst)\n",
    "            return inst\n",
    "\n",
    "inst= visualize_predictions(r\"D:\\Source\\Test\\data\\Output\\Fractal\\Model_VNIR_params\\model_VNIR_49.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polygon_extractor import PolygonExtractor\n",
    "predicted_image = nd.array(inst)  \n",
    "ground_truth_image = nd.array(mask_dict[6982].image)\n",
    "extractor  = PolygonExtractor()\n",
    "pred_polygons, gt_polygons =extractor.getPolygons(predicted_image, ground_truth_image)\n",
    "print(len(pred_polygons))\n",
    "print(len(gt_polygons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compute_iou import ComputeIou\n",
    "comIou =ComputeIou(pred_polygons,gt_polygons)\n",
    "iou_results= comIou.calculateIOU()\n",
    "\n",
    "# Evaluate using the precomputed IoU results\n",
    "precision, recall, f1_score = comIou.evaluate_segmentation_from_iou(iou_results, iou_threshold=0.5)\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1-Score: {f1_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satellite_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
