{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MXNET_CUDNN_LIB_CHECKING\"] = \"0\"\n",
    "os.environ[\"MXNET_CUDNN_AUTOTUNE_DEFAULT\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Experiment configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import const\n",
    "from experimentConfig import ExperimentConfig\n",
    "\n",
    "config_2022 = ExperimentConfig(\n",
    "    input_directory = const.images_2022,\n",
    "    year=2022,\n",
    "    isVnir=True,\n",
    "    numberOfimages=648,\n",
    "    all_bands=True,\n",
    "    use_hyperparameter_tuning=False,\n",
    "    use_augmentation=False,\n",
    "    use_mixup_cutmix=False\n",
    ")\n",
    "print(config_2022)\n",
    "config_2022.makeOutputDir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load image and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_Dictionary import ImageDict\n",
    "images_2022= ImageDict(False)\n",
    "image_dict_2022  = images_2022.load_tif_files(config_2022)\n",
    "masks_2022 = ImageDict(True)\n",
    "mask_dict_2022  = masks_2022.load_tif_files(config_2022, image_dict_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `config_2022.use_augmentation` is a boolean indicating whether to use data augmentation.\n",
    "from train_val_datalaoder import TrainValDataLoader\n",
    "trainValDataloader = TrainValDataLoader(image_dict_2022, mask_dict_2022, config_2022.use_augmentation)\n",
    "\n",
    "# Prepare the data loaders with a specified batch size\n",
    "train_loader, val_loader = trainValDataloader.prepare_data_loaders(batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 2022 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import mxnet as mx\n",
    "from mxnet import context\n",
    "from mxnet.base import MXNetError\n",
    "\n",
    "from mx_Train import myTrain\n",
    "from my_Save import saveAsCSV, SaveModels\n",
    "from myPlots import lossPlot\n",
    "\n",
    "ctx=context.gpu()\n",
    "mx.nd.waitall()\n",
    "\n",
    "# Maximum number of retries\n",
    "max_retries = 5\n",
    "retry_count = 0\n",
    "\n",
    "# Retry logic\n",
    "while retry_count < max_retries:\n",
    "    try:\n",
    "        mxTn = myTrain(train_loader, val_loader, config_2022)\n",
    "        loss_each_epoch, model_list, epoch = mxTn.train(ctx, epochs = 50)\n",
    "        saveAsCSV([\"Current Epoch\", \"Training Loss\", \"Validation Loss\"], config_2022.lossFile, loss_each_epoch)\n",
    "        SaveModels(config_2022.output_models, model_list)\n",
    "        lossPlot(loss_each_epoch, config_2022.output_directory)\n",
    "        break\n",
    "    except MXNetError  as e:\n",
    "        if 'CUDNN_STATUS_EXECUTION_FAILED' in str(e):\n",
    "            print(f\"cuDNN execution failed. Retrying... ({retry_count + 1}/{max_retries})\")\n",
    "            mx.nd.waitall()  # Clear GPU memory\n",
    "            time.sleep(5) # Wait for a few seconds before retrying\n",
    "            retry_count += 1 # Increment the retry counter\n",
    "        else:\n",
    "            raise  # If it's another error, raise it\n",
    "\n",
    "# Check if maximum retries were reached\n",
    "if retry_count == max_retries:\n",
    "    print(\"Maximum retries reached. Training failed due to cuDNN error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying model in 2022 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from postprocessing import predictedImages\n",
    "vPredictedImages = predictedImages(config_2022, trainValDataloader.val_ids)\n",
    "vPredictedImages.save_predictions(config_2022, ctx, 0.6, 0.1, image_dict_2022, mask_dict_2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying model in 2010 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_2010 = ExperimentConfig(\n",
    "    input_directory = const.images_2010,\n",
    "    year=2010,\n",
    "    isVnir=True,\n",
    "    numberOfimages=648,\n",
    "    use_hyperparameter_tuning=False,\n",
    "    use_augmentation=False,\n",
    "    use_mixup_cutmix=False\n",
    ")\n",
    "print(config_2010)\n",
    "config_2010.makeOutputDir()\n",
    "images_2010 = ImageDict(False)\n",
    "image_dict_2010 = images_2010.load_tif_files(config_2010)\n",
    "\n",
    "vPredictedImages.save_predictions(config_2010, ctx, list(image_dict_2010.keys()), 0.6, 0.1, image_dict_2010)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satellite_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
