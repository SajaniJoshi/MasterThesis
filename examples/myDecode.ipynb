{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MXNET_CUDNN_LIB_CHECKING\"] = \"0\"\n",
    "os.environ[\"MXNET_CUDNN_AUTOTUNE_DEFAULT\"] = \"0\"\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import  autograd, context\n",
    "from mxnet.base import MXNetError\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import myModel\n",
    "from image_Dictionary import ImageDict\n",
    "import const\n",
    "from my_Save import saveAsCSV, SaveModels\n",
    "from mx_Train import myTrain\n",
    "from decode.postprocessing.instance_segmentation import InstSegm\n",
    "from myPlots import lossPlot, visualize_all, plot_images_with_masks, plotPredictedImape, plotIOUS\n",
    "from iou import  get_iou\n",
    "\n",
    "ctx=context.gpu()\n",
    "mx.nd.waitall()\n",
    "numberOfimages = 648\n",
    "\n",
    "isVnir = False\n",
    "imageType = \"NDV\"\n",
    "if isVnir:\n",
    "    imageType = \"VNIR\"\n",
    "\n",
    "input_directory = const.images_2022\n",
    "output_directory = os.path.join(const.result_2022, imageType, str(numberOfimages))\n",
    "output_models= os.path.join(output_directory,\"models\")\n",
    "result_path = os.path.join(output_directory, \"result\")\n",
    "lossFile =   os.path.join(output_directory,\"loss.csv\") \n",
    "#print('imageType:', imageType)\n",
    "\n",
    "def makedir(path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    #print(path)\n",
    "    \n",
    "for i in [output_directory, output_models, result_path]:\n",
    "    makedir(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to load images and masks and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_2022= ImageDict(const.images_2022,  False)\n",
    "image_dict_2022  = images_2022.load_tif_files(imageType, numberOfimages = numberOfimages)\n",
    "masks_2022 = ImageDict(const.masks_2022, True)\n",
    "mask_dict_2022  = masks_2022.load_tif_files(imageType, image_dict_2022, numberOfimages = numberOfimages)\n",
    "train_ids, val_ids = train_test_split(list(mask_dict_2022.keys()), test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_2010 = ImageDict(const.images_2010, False)\n",
    "testimages = 648\n",
    "image_dict_2010 = images_2010.load_tif_files(imageType, numberOfimages=testimages)\n",
    "output_directory_2010 = os.path.join(const.result_2010, imageType)\n",
    "makedir(output_directory_2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(ids, image_dict):\n",
    "    data=  np.array([image_dict[id].image for id in ids])\n",
    "    return mx.nd.array(data)\n",
    "\n",
    "train_images =get_images(train_ids, image_dict_2022)\n",
    "train_masks = get_images(train_ids, mask_dict_2022)\n",
    "val_images = get_images(val_ids, image_dict_2022)\n",
    "val_masks = get_images(val_ids, mask_dict_2022)\n",
    "\n",
    "batch_size=4\n",
    "try:\n",
    "    train_dataset = mx.gluon.data.ArrayDataset(train_images, train_masks)\n",
    "    train_loader = mx.gluon.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=0,shuffle=True)\n",
    "    val_loader = mx.gluon.data.DataLoader(mx.gluon.data.ArrayDataset(val_images, val_masks), batch_size=batch_size, num_workers=0, shuffle=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error creating data loaders: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of retries\n",
    "max_retries = 5\n",
    "retry_count = 0\n",
    "\n",
    "# Retry logic\n",
    "while retry_count < max_retries:\n",
    "    try:\n",
    "        mxTn = myTrain(train_loader, val_loader)\n",
    "        loss_each_epoch, model_list, epoch = mxTn.train(ctx, epochs = 50)\n",
    "        saveAsCSV([\"Current Epoch\", \"Training Loss\", \"Validation Loss\"], lossFile, loss_each_epoch)\n",
    "        SaveModels(output_models, model_list)\n",
    "        lossPlot(loss_each_epoch, output_directory)\n",
    "        break\n",
    "    except MXNetError  as e:\n",
    "        if 'CUDNN_STATUS_EXECUTION_FAILED' in str(e):\n",
    "            print(f\"cuDNN execution failed. Retrying... ({retry_count + 1}/{max_retries})\")\n",
    "            mx.nd.waitall()  # Clear GPU memory\n",
    "            time.sleep(5) # Wait for a few seconds before retrying\n",
    "            retry_count += 1 # Increment the retry counter\n",
    "        else:\n",
    "            raise  # If it's another error, raise it\n",
    "\n",
    "# Check if maximum retries were reached\n",
    "if retry_count == max_retries:\n",
    "    print(\"Maximum retries reached. Training failed due to cuDNN error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_file_name():\n",
    "    files = os.listdir(output_models)  # Get all files in the folder\n",
    "    if files:\n",
    "        last_file = os.path.join(output_models, f'model_VNIR_{len(files)-1}.params')\n",
    "        print(f\"This model is using: {last_file}\")\n",
    "        return last_file\n",
    "    else:\n",
    "        print(\"The folder is empty.\")\n",
    "\n",
    "def get_img_metadata(id, is2022):\n",
    "    if is2022:\n",
    "        img = images_2022.getImage(id, image_dict_2022, ctx)\n",
    "        mask = masks_2022.getImage(id, mask_dict_2022, ctx)\n",
    "        currentMetadata = image_dict_2022[id]\n",
    "    else:\n",
    "        img = images_2010.getImage(id, image_dict_2010, ctx)\n",
    "        currentMetadata = image_dict_2010[id]\n",
    "        mask = None\n",
    "    return img, mask, currentMetadata\n",
    "\n",
    "def get_ref_path(is2022):\n",
    "    ref_path = const.output_ref_2022    \n",
    "    if not is2022:\n",
    "        ref_path = const.output_ref_2010\n",
    "    return ref_path\n",
    "\n",
    "def visualize_predictions(result_path, val_ids, t_ext , t_bound , is2022):    \n",
    "    print(f\"Starting visualization with t_ext = {t_ext}, t_bound = {t_bound}\")\n",
    "    modelPath = rf\"{get_model_file_name()}\"\n",
    "    ref_path = get_ref_path(is2022)   \n",
    "\n",
    "    netPredict = myModel.MyFractalResUNetcmtsk(True, modelPath, ctx)\n",
    "    ious=[]\n",
    "    ious.append({\"ID\": f't_ext: {t_ext}',\"IOU\": f't_bound: {t_bound}'}) \n",
    "    plotColl = []\n",
    "\n",
    "    for id in val_ids:  # Limit to 'num_images' for visualization\n",
    "        print(f\"Processing image ID: {id}\")\n",
    "        try:\n",
    "            img, mask, currentMetadata = get_img_metadata(id, is2022)\n",
    "           \n",
    "            with autograd.predict_mode():  \n",
    "                outputs = netPredict.net(img) \n",
    "                pred_segm  = np.array(outputs[0][0,1,:,:].asnumpy())\n",
    "                pred_bound =  np.array(outputs[1][0,1,:,:].asnumpy())\n",
    "                pred_dists =  np.array(outputs[2][0,1,:,:].asnumpy()) \n",
    "                pred_segm = 1-pred_segm\n",
    "                #print(\"Shape of pred_segm:\", pred_segm.shape, \"Shape of pred_bound:\", pred_bound.shape, \"Shape of binary_extent_mask:\", pred_segm.shape)\n",
    "                #print(\"NaNs in pred_segm:\", np.isnan(pred_segm).sum(), \"NaNs in binary_extent_mask:\", np.isnan(pred_segm).sum())\n",
    "                inst =InstSegm(pred_segm, pred_bound, t_ext=t_ext, t_bound=t_bound)   # perform instance segmentation\n",
    "                #print(\"NaNs in inst:\", np.isnan(inst).sum())\n",
    "                inst = np.nan_to_num(inst, nan=0)\n",
    "                if is2022:\n",
    "                    imgColl = plotPredictedImape(id, img, mask, pred_segm, pred_bound, pred_dists, inst, ref_path)\n",
    "                    plotColl.append(imgColl)\n",
    "                output_shapefile_path = visualize_all(id, img, currentMetadata, outputs, pred_segm, pred_bound, inst, result_path)\n",
    "                print(\"Start IOU calculation\")\n",
    "                csv_file_path = os.path.join(result_path, str(id), \"iou.csv\")\n",
    "                iou_score= get_iou(os.path.join(ref_path, f'tile_{id}.shp'), os.path.join(output_shapefile_path, f'{str(id)}.shp'))\n",
    "                ious.append({ \"ID\": id,\"IOU\": iou_score })\n",
    "                saveAsCSV([\"ID\", \"IOU\"], csv_file_path, ious, True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image ID {id}: {e}\")\n",
    "    \n",
    "    return plotColl\n",
    "       \n",
    "def visualize(result_path, val_ids,  t_ext , t_bound , is2022 = True):\n",
    "    random_val_ids = random.choice(val_ids) # Choose a random validation ID\n",
    "    return visualize_predictions(result_path, val_ids ,t_ext = t_ext, t_bound = t_bound, is2022 = is2022)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying model in 2022 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is for vnir: t_ext = 0.6, t_bound = 0.1\n",
    "#6612\n",
    "results_2022 = visualize(result_path, val_ids, t_ext = 0.6, t_bound = 0.1, is2022 = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotIOUS(r\"D:\\Source\\Output\\Result_2022\\VNIR\\648\\result\\6614\\iou.csv\", r\"D:\\Source\\Output\\Result_2022\\VNIR\\648\\iou_Hist_2022.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotIOUS(r\"D:\\Source\\Output\\Result_2022\\NDV\\648\\result\\6782\\iou.csv\", r\"D:\\Source\\Output\\Result_2022\\NDV\\648\\result_ndv_2022.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotIOUS(r\"D:\\Source\\Output\\Result_2010\\VNIR\\99\\iou.csv\", r\"D:\\Source\\Output\\Result_2010\\VNIR\\IOU_2010.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_with_masks(results_2022[:3] , r\"D:\\Source\\Output\\Result_2022\\NDV\\648\\results_ovelap_2022.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_with_masks(results_2022[:3] , r\"D:\\Source\\Output\\Result_2022\\VNIR\\648\\results_2022.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying model in 2010 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(image_2010_dict.keys())\n",
    "results_2010 =visualize(output_directory_2010, list(image_dict_2010.keys()),  t_ext = 0.6, t_bound = 0.1, is2022= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mxnet_36",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
