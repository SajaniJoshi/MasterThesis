{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c75317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:32:40.423674Z",
     "start_time": "2024-10-11T22:32:40.367149Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, nd, autograd\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data import DataLoader, ArrayDataset\n",
    "from mxnet.lr_scheduler import FactorScheduler\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7714aebfd75e4",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "image_dir = r\"D:\\Source\\Test\\TextMxnet\\data\\2022\\BB\\08X_Features_Multi\"\n",
    "mask_dir = r\"D:\\Source\\Test\\TextMxnet\\data\\2022\\BB\\XX_Reference_Masks_ResUNetA\"\n",
    "loss_path = r\"D:\\Source\\Test\\TextMxnet\\data\\2022\\BB\\Output\\Loss\\loss_plot5.png\"\n",
    "result_path = r\"D:\\Source\\Test\\TextMxnet\\data\\2022\\BB\\Output\\Result\"\n",
    "trained_model_path = r\"D:\\Source\\Test\\TextMxnet\\data\\2022\\BB\\Output\\Model_params\\resunet_model.params\"\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 8\n",
    "learning_rate = 0.000001\n",
    "\n",
    "try:\n",
    "    ctx = mx.gpu() if mx.context.num_gpus() > 0 else mx.cpu()\n",
    "except:\n",
    "    ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7341036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ResUNetA model\n",
    "class ResUNetA(nn.HybridBlock):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ResUNetA, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.encoder = nn.HybridSequential()\n",
    "            self.encoder.add(nn.Conv2D(64, kernel_size=3, padding=1))\n",
    "            self.encoder.add(nn.BatchNorm())\n",
    "            self.encoder.add(nn.Activation('relu'))\n",
    "            self.encoder.add(nn.Dropout(0.5))  # Added dropout to stabilize training\n",
    "\n",
    "            self.decoder = nn.HybridSequential()\n",
    "            self.decoder.add(nn.Conv2D(64, kernel_size=3, padding=1))\n",
    "            self.decoder.add(nn.BatchNorm())\n",
    "            self.decoder.add(nn.Activation('relu'))\n",
    "            self.decoder.add(nn.Dropout(0.5))  # Added dropout to stabilize training\n",
    "\n",
    "            self.output = nn.Conv2D(1, kernel_size=1)  # Output for binary segmentation\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8398101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract numeric identifier from filenames\n",
    "def extract_number(filename):\n",
    "    match = re.search(r'\\d+', filename)\n",
    "    return int(match.group()) if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3468eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TIFF files\n",
    "def load_tif_files_with_id(directory, num_files=None):\n",
    "    file_dict = {}\n",
    "    count = 0\n",
    "    try:\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(\".tif\"):\n",
    "                file_id = extract_number(filename)\n",
    "                if file_id is not None:\n",
    "                    with rasterio.open(os.path.join(directory, filename)) as src:\n",
    "                        image = src.read()  # Load as NumPy array\n",
    "                        if file_id in file_dict:\n",
    "                            file_dict[file_id].append(image)\n",
    "                            #print(f'fid: {file_id}. count: {len(file_dict[file_id])}')\n",
    "                        else:\n",
    "                             file_dict[file_id] = [image]  \n",
    "                       # Limit the number of files loaded, if specified\n",
    "                count += 1\n",
    "                if num_files and count >= num_files:\n",
    "                    break\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading TIFF files: {e}\")\n",
    "    return file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adec77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and masks from directories with numeric identifiers as keys\n",
    "images_dict = load_tif_files_with_id(image_dir, num_files=10)\n",
    "masks_dict = load_tif_files_with_id(mask_dir, num_files=10)\n",
    "#print(len(images_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2864da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate NDVI given NIR and Red bands\n",
    "def calculate_ndvi(image, nir_index, red_index):\n",
    "    nir = image[nir_index]  # NIR band\n",
    "    red = image[red_index]  # Red band\n",
    "    # Calculate NDVI with division by zero handling\n",
    "    ndvi = (nir - red) / (nir + red + 1e-5)  # Adding a small value to avoid division by zero\n",
    "    return ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e87cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming NIR is the 4th band and Red is the 1st band\n",
    "nir_band_index = 3\n",
    "red_band_index = 0\n",
    "\n",
    "for key, values in images_dict.items():\n",
    "    # Verify the image structure before proceeding\n",
    "    if len(values) < 2:\n",
    "        print(f\"Warning: Insufficient images for key {key}\")\n",
    "        continue\n",
    "\n",
    "    # Calculate NDVI for each image\n",
    "    try:\n",
    "        ndv_ndvi = calculate_ndvi(values[0], nir_band_index, red_band_index)\n",
    "        vnir_ndvi = calculate_ndvi(values[1], nir_band_index, red_band_index)\n",
    "        mask_ndvi = calculate_ndvi(masks_dict[key][0], nir_band_index, red_band_index)\n",
    "    except IndexError:\n",
    "        print(f\"Error: Invalid band indices for key {key}\")\n",
    "        continue\n",
    "\n",
    "    # Plot the NDVI results with color bars\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    ndv_img = plt.imshow(ndv_ndvi, cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "    plt.colorbar(ndv_img, label=\"NDVI\")\n",
    "    plt.title(f\"NDVI - NDV Image (fid: {key})\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    vnir_img = plt.imshow(vnir_ndvi, cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "    plt.colorbar(vnir_img, label=\"NDVI\")\n",
    "    plt.title(f\"NDVI - VNIR Image (fid: {key})\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    mask_img = plt.imshow(mask_ndvi, cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "    plt.colorbar(mask_img, label=\"NDVI\")\n",
    "    plt.title(f\"NDVI - Mask Image (fid: {key})\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c0106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_dict(images_dict, masks_dict):\n",
    "    images_preprocessed = {}\n",
    "    masks_preprocessed = {}\n",
    "\n",
    "    try:\n",
    "        for key in images_dict.keys():\n",
    "           # Get the image and corresponding mask\n",
    "            #print(f'fid: {key}. count: {len(images_dict[key])}')\n",
    "            img = np.array(images_dict[key])  # Convert img to a NumPy array if it's not already\n",
    "            #print(img.shape)\n",
    "            msk = np.array(masks_dict.get(key))  # Convert msk to a NumPy array if it's not already\n",
    "            #print(msk.shape)\n",
    "            # Normalize image to range [0, 1]\n",
    "            img = img / 255.0\n",
    "\n",
    "            # Handle NaN or infinite values in the mask\n",
    "            msk = np.nan_to_num(msk)  # Replace NaN, inf, -inf with 0\n",
    "\n",
    "            # If the mask has multiple channels, reduce to a single channel by summing across channels\n",
    "            if msk.ndim > 2 and msk.shape[0] > 1:\n",
    "                msk = np.sum(msk, axis=0, keepdims=True)\n",
    "\n",
    "            # Convert summed mask to binary (0 or 1)\n",
    "            msk = np.where(msk > 0, 1, 0)\n",
    "            # Store preprocessed data in output dictionaries\n",
    "            images_preprocessed[key] = img.astype('float32')\n",
    "            masks_preprocessed[key] = msk.astype('float32')\n",
    "    except Exception as e:\n",
    "        print(f\"Error during preprocessing: {e}\")\n",
    "\n",
    "    return images_preprocessed, masks_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15488e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the loaded images and masks\n",
    "images_preprocessed, masks_preprocessed = preprocess_data_dict(images_dict, masks_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab7d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_dict(images_dict, masks_dict, test_size=0.2, random_state=None):\n",
    "    \"\"\"\n",
    "    Splits dictionaries of images and masks into training and validation sets while keeping keys.\n",
    "\n",
    "    Args:\n",
    "        images_dict (dict): Dictionary of images, with keys as identifiers.\n",
    "        masks_dict (dict): Dictionary of masks, with keys as identifiers.\n",
    "        test_size (float): Proportion of the data to include in the validation split.\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        dict: Training split of the images.\n",
    "        dict: Validation split of the images.\n",
    "        dict: Training split of the masks.\n",
    "        dict: Validation split of the masks.\n",
    "    \"\"\"\n",
    "    # Get the list of keys\n",
    "    keys = list(images_dict.keys())\n",
    "    \n",
    "    # Split keys into training and validation sets\n",
    "    keys_train, keys_val = train_test_split(keys, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Create train and validation dictionaries for images and masks\n",
    "    images_train = {key: images_dict[key] for key in keys_train}\n",
    "    images_val = {key: images_dict[key] for key in keys_val}\n",
    "    masks_train = {key: masks_dict[key] for key in keys_train}\n",
    "    masks_val = {key: masks_dict[key] for key in keys_val}\n",
    "    \n",
    "    for key in images_train.keys():\n",
    "        print(f\"image train fid:{key}. Size: {len(images_train[key])}\")\n",
    "    for key in images_val.keys():\n",
    "        print(f\"val fid:{key}. Size: {len(images_val[key])}\")\n",
    "    for key in masks_train.keys():\n",
    "        print(f\"mask train fid:{key}. Size: {len(masks_train[key])}\")\n",
    "    for key in masks_val.keys():\n",
    "        print(f\"mask val fid:{key}. Size: {len(masks_val[key])}\")\n",
    "    \n",
    "    return images_train, images_val, masks_train, masks_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cf8c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split images and masks into training and validation sets\n",
    "X_train, X_val, Y_train, Y_val = train_test_split_dict(images_preprocessed, masks_preprocessed, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761774c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute IoU\n",
    "def iou_metric(pred, mask):\n",
    "    try:\n",
    "        pred = (pred > 0.5).astype(np.uint8)\n",
    "        intersection = np.logical_and(mask, pred)\n",
    "        union = np.logical_or(mask, pred)\n",
    "        iou_score = np.sum(intersection) / np.sum(union)\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing IoU: {e}\")\n",
    "        iou_score = 0\n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for validation\n",
    "def validate(model, val_data, ctx):\n",
    "    iou_scores = []\n",
    "    try:\n",
    "        for data, label in val_data:\n",
    "            data = data.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "\n",
    "            pred = model(data)\n",
    "            pred = nd.sigmoid(pred)\n",
    "            print(f\"Sigmoid output - min: {nd.min(pred).asscalar()}, max: {nd.max(pred).asscalar()}\")\n",
    "            pred = pred > 0.5\n",
    "\n",
    "            iou = iou_metric(pred.asnumpy(), label.asnumpy())\n",
    "            iou_scores.append(iou)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during validation: {e}\")\n",
    "    return np.mean(iou_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38166f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Over Time')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "     # Adding text to the right corner\n",
    "    info_text = f'Epochs: {epochs}\\nBatch Size: {batch_size}\\nLearning Rate: {learning_rate}'\n",
    "    plt.text(len(train_losses) - 1, max(train_losses), info_text,\n",
    "             ha='right', va='top', fontsize=10, bbox=dict(facecolor='white', alpha=0.5))\n",
    "    plt.savefig(loss_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4658295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(xDict, yDict, batch_size, isTrue):\n",
    "    # Convert dictionary values to lists and preprocess them\n",
    "    x_values, y_values = list(xDict.values()), list(yDict.values())\n",
    "    \n",
    "    # Preprocess data to ensure correct shape\n",
    "    #x_values, y_values = zip(*[preprocess_data(x, y) for x, y in zip(x_values, y_values)])\n",
    "    \n",
    "    # Create the DataLoader with the reshaped data\n",
    "    data_loader = mx.gluon.data.DataLoader(mx.gluon.data.ArrayDataset(x_values, y_values), \n",
    "                                           batch_size=batch_size, shuffle=isTrue)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ee665362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data shape: (4, 2, 4, 256, 256)\n",
      "Original Label shape: (4, 1, 6, 256, 256)\n",
      "Reshaped Data shape: (4, 8, 256, 256)\n",
      "Reshaped Label shape before channel adjustment: (4, 6, 256, 256)\n",
      "Final Label shape: (4, 1, 256, 256)\n",
      "Data shape: (4, 8, 256, 256)\n",
      "Label shape: (4, 1, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "train_data = get_data_loader(X_train, Y_train, batch_size, True)\n",
    "val_data = get_data_loader(X_val, Y_val, batch_size, False)\n",
    "\n",
    "for i, (data, label) in enumerate(train_data):\n",
    "    print(\"Original Data shape:\", data.shape)\n",
    "    print(\"Original Label shape:\", label.shape)\n",
    "    \n",
    "    # Reshape `data` to combine the extra dimension without altering the batch size\n",
    "    if data.ndim == 5:\n",
    "        data = data.reshape((data.shape[0], -1, data.shape[3], data.shape[4]))  # Combine channels\n",
    "        print(\"Reshaped Data shape:\", data.shape)\n",
    "    \n",
    "    # Reshape `label` to combine extra dimensions without altering the batch size\n",
    "    if label.ndim == 5:\n",
    "        label = label.reshape((label.shape[0], -1, label.shape[3], label.shape[4]))  # Combine channels if needed\n",
    "        print(\"Reshaped Label shape before channel adjustment:\", label.shape)\n",
    "        \n",
    "        # If `label` has more channels, select only the first channel\n",
    "        if label.shape[1] > 1:\n",
    "            label = label[:, 0:1, :, :]  # Keep only the first channel\n",
    "        print(\"Final Label shape:\", label.shape)\n",
    "\n",
    "    # Send data and label to the designated device (CPU or GPU)\n",
    "    data = data.as_in_context(ctx)\n",
    "    label = label.as_in_context(ctx)\n",
    "\n",
    "    print(\"Data shape:\", data.shape)\n",
    "    print(\"Label shape:\", label.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293ab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = ResUNetA()\n",
    "    try:\n",
    "        model.initialize(ctx=ctx)\n",
    "        model.hybridize()\n",
    "        print('model is initiated')\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing or hybridizing model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d46269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with loss plotting and hyperparameter control\n",
    "def train_model():\n",
    "    model = get_model()\n",
    "    # Define loss function and trainer\n",
    "    loss_fn = gluon.loss.SigmoidBinaryCrossEntropyLoss(from_sigmoid=True)\n",
    "    # Reduce learning rate by a factor of 0.5 every 10 epochs\n",
    "    lr_scheduler = FactorScheduler(step=10, factor=0.5)\n",
    "    trainer = gluon.Trainer(model.collect_params(), 'adam', {'learning_rate': learning_rate,\n",
    "                                                             'clip_gradient': 0.1})\n",
    "\n",
    "    # DataLoaders for training and validation\n",
    "    try:\n",
    "        train_data =get_data_loader(X_train,Y_train, batch_size, True) \n",
    "        val_data = get_data_loader(X_val, Y_val, batch_size, False) \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating data loaders: {e}\")\n",
    "        return\n",
    "\n",
    "    train_losses = []\n",
    "    val_ious = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        try:\n",
    "            accumulation_steps = 4  # Accumulate gradients over 4 batches\n",
    "            for i, (data, label) in enumerate(train_data):\n",
    "                print(\"Original Data shape:\", data.shape)\n",
    "                print(\"Original Label shape:\", label.shape)\n",
    "                \n",
    "                # Reshape `data` and `label` to 4D if they have an extra dimension\n",
    "                if data.ndim == 5:\n",
    "                    data = data.reshape((-1, data.shape[2], data.shape[3], data.shape[4]))  # Flatten batch and extra dim\n",
    "                    print(\"Reshaped Data shape:\", data.shape)\n",
    "                if label.ndim == 5:\n",
    "                    label = label.reshape((-1, label.shape[2], label.shape[3], label.shape[4]))  # Flatten label shape\n",
    "                    print(\"Reshaped Label shape:\", label.shape)\n",
    "                    \n",
    "                # Send data and label to the designated device (CPU or GPU)\n",
    "                data = data.as_in_context(ctx)\n",
    "                label = label.as_in_context(ctx)\n",
    "                print(\"Data shape:\", data.shape)\n",
    "                print(\"Label shape:\", label.shape)\n",
    "\n",
    "                with autograd.record(): # Start recording the operations for autograd\n",
    "                    output = model(data) # Forward pass: compute the model output\n",
    "                    print('I am here3')\n",
    "                    output_sigmoid = nd.sigmoid(output)\n",
    "                    # Print output stats before and after sigmoid\n",
    "                    print(f\"Output before sigmoid - min: {nd.min(output).asscalar()}, max: {nd.max(output).asscalar()}\")\n",
    "                    print(f\"Output after sigmoid - min: {nd.min(output_sigmoid).asscalar()}, max: {nd.max(output_sigmoid).asscalar()}\")\n",
    "\n",
    "                    loss = loss_fn(output_sigmoid, label)\n",
    "                    print(f'loss: {loss}')\n",
    "                loss.backward()  # Backward pass: compute the gradients\n",
    "                print(f'loss after backward: {loss}')\n",
    "                if (i + 1) % accumulation_steps == 0:\n",
    "                    trainer.step(batch_size * accumulation_steps)  # Effective batch size\n",
    "                else:\n",
    "                    trainer.step(batch_size)  # Update model parameters\n",
    "\n",
    "                # Check for NaNs in output and loss\n",
    "                print(f\"Model output stats - min: {nd.min(output).asscalar()}, max: {nd.max(output).asscalar()}\")\n",
    "                epoch_loss += nd.mean(loss).asscalar()\n",
    "                print(f'Batch {i}, epoch_loss: {epoch_loss}')\n",
    "            print(f'Epoch {epoch + 1}, total epoch_loss: {epoch_loss}')\n",
    "            print(f'train data: {train_data}')\n",
    "\n",
    "            avg_loss = epoch_loss / len(train_data)\n",
    "            val_iou = validate(model, val_data, ctx)\n",
    "\n",
    "            train_losses.append(avg_loss)\n",
    "            val_ious.append(val_iou)\n",
    "\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Validation IoU: {val_iou:.4f}\")\n",
    "\n",
    "            # Save the model parameters\n",
    "            model.save_parameters(trained_model_path)\n",
    "            print(f\"Model parameters saved to {trained_model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during training epoch {epoch + 1}: {e}\")\n",
    "\n",
    "    # Plot training loss\n",
    "    plot_loss(train_losses)\n",
    "\n",
    "    # Return model and metrics\n",
    "    return model, train_losses, val_ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f14d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training with hyperparameters\n",
    "model= None\n",
    "train_losses= None\n",
    "val_ious = None\n",
    "try:\n",
    "    start_time = time.time()\n",
    "\n",
    "   # Print the start time with a formatted string\n",
    "    print(f\"Start time for training model: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}\")\n",
    "\n",
    "    model, train_losses, val_ious = train_model()\n",
    "    end_time = time.time()\n",
    "    print(f\"End time for train model: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))}\")\n",
    "    execution_time = end_time - start_time  # Calculate the duration\n",
    "    print(f\"Execution time for train model: {execution_time} seconds\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during model training: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de11430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions():\n",
    "    try:\n",
    "        # Create lists of (fid, image, mask) tuples\n",
    "        data = [(fid, X_val[fid], Y_val[fid]) for fid in X_val.keys() if fid in Y_val]\n",
    "    \n",
    "        # Unpack the data into ArrayDataset\n",
    "        fids, images, masks = zip(*data)\n",
    "        print(fids)\n",
    "        dataset = ArrayDataset(fids, images, masks)\n",
    "    \n",
    "        # Create DataLoader\n",
    "        data_loader = DataLoader(dataset, batch_size, shuffle=False)\n",
    "\n",
    "        model = ResUNetA()\n",
    "        model.load_parameters(trained_model_path, mx.cpu())\n",
    "        model.hybridize()\n",
    "    except Exception as e:\n",
    "        print(\"Error during model setup or loading parameters:\", str(e))\n",
    "        return\n",
    "\n",
    "    for i, (fid, data, label) in enumerate(data_loader):\n",
    "        try:\n",
    "            # Ensure fid has only one element so we can use .asscalar()\n",
    "            if fid.size == 1:\n",
    "                id = fid.asscalar()  # Convert single-element NDArray to integer\n",
    "            else:\n",
    "                raise ValueError(\"fid contains more than one element; expected a single element.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting single-element id at iteration {i}:\", str(e))\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            data = data.as_in_context(mx.cpu())\n",
    "            label = label.as_in_context(mx.cpu())\n",
    "        except Exception as e:\n",
    "            print(f\"Error moving data or label to context at iteration {i}:\", str(e))\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            with autograd.record():\n",
    "                prediction = model(data)\n",
    "                prediction = nd.sigmoid(prediction)\n",
    "                prediction = (prediction > 0.5).astype('uint8')\n",
    "        except Exception as e:\n",
    "            print(f\"Error during prediction at iteration {i}:\", str(e))\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Convert NDArray to numpy arrays for visualization\n",
    "            data_np = data[0].asnumpy().squeeze()\n",
    "            label_np = label[0].asnumpy().squeeze()\n",
    "            prediction_np = prediction[0].asnumpy().squeeze()\n",
    "\n",
    "            # Handle cases where data_np has 4 channels by using only the first 3 (assuming RGB + Alpha)\n",
    "            if data_np.ndim == 3 and data_np.shape[0] == 4:\n",
    "                data_np = data_np[:3, :, :]  # Take only the first 3 channels\n",
    "            \n",
    "            # If data_np has 3 channels, transpose it to (height, width, channels)\n",
    "            if data_np.ndim == 3 and data_np.shape[0] == 3:\n",
    "                data_np = data_np.transpose((1, 2, 0))\n",
    "            \n",
    "            # Check and normalize data_np if needed\n",
    "            print(f\"Original image (data_np) min: {data_np.min()}, max: {data_np.max()}\")\n",
    "            if data_np.max() > 1:\n",
    "                data_np = data_np / 255.0  # Normalize if values are in [0, 255]\n",
    "\n",
    "            # Check and normalize label_np if needed\n",
    "            print(f\"Mask (label_np) min: {label_np.min()}, max: {label_np.max()}\")\n",
    "            if label_np.max() > 1:\n",
    "                label_np = label_np / 255.0  # Normalize if values are in [0, 255]\n",
    "\n",
    "            # Ensure prediction is also scaled between 0 and 1 for visualization\n",
    "            prediction_np = prediction_np / prediction_np.max()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error accessing images or masks dictionaries at iteration {i}:\", str(e))\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "\n",
    "            # Display the real image\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(images_dict[id], cmap='gray' if data_np.ndim == 2 else None)\n",
    "            plt.title(f\"Original: {id}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            # Display the corresponding mask\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(masks_dict[id], cmap='viridis', vmin=0, vmax=1)\n",
    "            plt.title(f\"Mask: {id}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            # Display the prediction\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(prediction_np, cmap='viridis', vmin=0, vmax=1)\n",
    "            plt.title(\"Prediction\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(result_path, f\"final{i}.png\"))\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error during visualization or saving figure at iteration {i}:\", str(e))\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec713d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    start_time1 = time.time()\n",
    "    print(f\"Start time for visualize_predictions: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time1))}\")\n",
    "    # Create Dataloader for predictions using validation dataset\n",
    "    visualize_predictions()\n",
    "    end_time1 = time.time()\n",
    "    print(f\"End time for visualize_predictions: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time1))}\")\n",
    "    execution_time1 = end_time1 - start_time1  # Calculate the duration\n",
    "    print(f\"Execution time for visualize_predictions: {execution_time1}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during model training: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satellite_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
